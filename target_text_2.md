大家好，欢迎来到AI阅读课。我是本讲的教师，名叫毛六。在这次的“技术准备”讲解中，我会详细阐述在接下来的课程中会反复出现的一些概念。我将按照系统阅读法、文本大法和GPT的顺序进行介绍。首先，我们来看一下什么是系统阅读法。在第一讲中，我们对系统阅读法已经做了一个简单的了解。简单来说，系统阅读法包含五种具体的阅读技法，分别是文本细读、抽样阅读、结构阅读、主题阅读和卡片大法。这五种技法的应用，实际上都是基于认知科学原理。

例如，文本细读，就是逐字逐句的阅读，并对其进行反复阅读，我们主要的目的是对话作者，充分利用我们大脑的常识、记忆容错率和情境适应的优势。抽样阅读则是带有假设的阅读，利用我们大脑强大的模式识别能力，通过识别并对比模式来获取知识。

结构阅读的技法是带着框架去读书，通过理解作者的思考方式，形成一个易于记忆的知识架构。主题阅读是围绕同一主题阅读多本书，通过相互参照找到关键知识点，它利用了认知科学的快速命名和模式识别原理。

卡片大法则是通过撰写笔记卡片的方式提取知识。每种阅读技法下，包含了更细颗粒度的阅读技巧，在课程的第二部分，我们也会详细解释如何结合AI技术来使用系统阅读法进行读书。另外，系统阅读法也非常适合进行灵活的组合使用。

下面，我们以《聪明的阅读者》这本书为例，具象化理解系统阅读法的应用。首先，当你手里拿到这本书的时候，你首先要做的是确定这本书是一种什么样的书，这是一个什么样的类型的书。明显的，我们可以知道，《聪明的阅读者》是杨志平老师撰写的关于阅读原理的书，这是一本学术专著。然后我们应确定学术专著的阅读顺序，阅读完后我们要将每个环节撰写的卡片整理成书评。

以上我们通过一些信息推断，这是一本学术专著。学术专著的阅读顺序又该如何确定呢？这需要我们对学术专著的特性有深入的了解。虽然学术专著是获取知识的一种重要图书类型，但阅读时我们可能会遇到一定的困难。
当我们阅读学术专著时，往往难以形成对整本书的全面理解，特别是其中充斥着各种专业术语和难懂的概念，这就需要我们掌握一定的学科知识才能理解。因此，我们推荐以下阅读顺序：先进行结构阅读，然后是抽样阅读，接着是文本细读，最后是主题阅读。在此过程中，"卡片大法"可以融入到各个阶段。

首先，我们确定"聪明的阅读者"是一本学术专著。然后，我们采用之前提及的结构阅读、抽样阅读、文本细读的顺序进行阅读。进入第三步，也就是真正开始阅读的阶段，我们对这本书进行了框架性、整体性的结构阅读。

在结构阅读中最重要也最难的部分就是确定作者的认知方式。要进行这样的判断，你需要对主流的认知方式有一定了解，例如，知道什么是思想实验，什么是符号思考，什么是田野调查等等。通过初步阅读，我做出判断，"聪明的阅读者"这本书的作者主要使用了思想实验、田野调查和文采美感这三种认知方式。

为什么会有这样的判断呢？这是我在阅读过程中发现的线索。例如，作者在文章开篇时会设问，导我们去思考某个问题，这就是思想实验的一种应用。再者，我了解到作者翻阅了人类文明的大部分优秀著作来撰写这本书，这就是田野调查的表现。且在阅读过程中，我发现作者创造了很多新颖的词汇，每篇文章的结尾都有优美的金句，全书的文笔简洁清晰，这又体现了文采美感的认知方式。

对于作者的认知方式做出判断后，我们就可以互动地阅读，比如评价作者的思想实验是否巧妙等。在完成结构阅读之后，我们可以进行抽样阅读，挑选感兴趣的章节阅读，比如我对第五章非常感兴趣。在抽样阅读时，我们带着假设进行，例如，假设作者真实的认知方式是否如我之前所判断：思想实验，田野调查和文采美感。我们可以阅读并验证这个假设。例如，作者在文章开篇时提出了一个问题：我们一生中能读到多少书，这陈述了思想实验的假设。

针对一个问题，他提出了一个见解：在时间有限、专注力有限的条件下，如果想尽可能多地阅读那些代表人类智慧的杰作，创维阅读是一种值得推荐的方法。以此，我们确定了作者确实运用了思想实验的认知方式，并且激发了我对这一章节的阅读兴趣。因此，我也计划对这一章进行仔细阅读。

如果有人希望了解阅读的底层原理，他们可以阅读《聪明阅读者》的第一篇《何为读？》。如果像我这样想要知道更多实用的阅读技巧，我们可以优先阅读第二篇《如何阅读》。而阅读完这本书之后，你可能会感兴趣，其他人是如何阅读的？阅读的原理是怎样的？如何在教育领域应用？你可以围绕阅读主题进行专题阅读。

在阅读过程中，笔头需要经常运动，这就需要了解一些笔记记录技巧，比如我们推荐的卡片法。我将介绍什么是卡片法。卡片法是一种以卡片为基本单位的写作方法，既可以用于阅读，也可以用于写作。在《聪明的阅读者》这本书中，杨志平教授提到，他会在阅读时不断在卡片上记下心得，写作时也会在卡片上写下一些灵感，然后快速检索过往卡片，并整理成文章。从西方的拉伯科夫艾科到中国的鲁迅、钱钟书，他们都是卡片法的实践者。

许多人提倡卡片法的原因是，它可以降低我们的认知负荷并降低写作难度。因此，写卡片时你可以随心所欲，想写什么就写什么。在《聪明的阅读者》中，作者详细介绍了九种卡片的写法，熟悉这些卡片的格式可以进一步降低我们的认知负荷，方便日后查阅。在接下来的第三讲到第七讲的课程中，我们会陆续收到撰写这九种卡片的任务，并在阅读和练习中进一步掌握卡片写作要领。

这九种卡片分别是：基础卡、行动卡、分析卡、人物卡、图示卡、事件卡、新词卡和引句卡。我们首先来看基础卡，其信息结构包括：标题、内容、参考和唯一编码。比如，我撰写的一张基础卡：标题是"卡片法之撰写基础卡"，内容是"今天阅读《聪明的阅读者》第八章，我了解到撰写基础卡的信息结构是标题加内容加参考加唯一编码"，参考则是杨志平的《聪明的阅读者》。
录音内容译为文字信息如下：

唯一编码是一个形如'2023-0526-00'的序列。接下来我要为你演示如何制作一张“行动卡”。行动卡旨在记录你从阅读中获得的行动启示。一张典型的行动卡包括标题、理论、行动、参考文献和唯一编码。在右侧示例中，我在基础卡片上增加了一个行动提示，然后写下一张行动卡。这一行动提示便是我们的行动，这就是一张标准的行动卡。你可以看到我会用不同的标记符号来创作这样的卡片，比如，标题我用'＃'来表示，理论我用“T”表示，行动我会用“A”表示，参考则用“REF"，而唯一编码则用“UUID”来表示，这些都是可以使用的符号。

然后我们看一下另一种卡片，“新知卡”。新知卡是记录我们在阅读中遇到的挑战、扩展认知的卡片，又称为反常识卡。例如，你通过阅读获得了什么新的理论模型、新的推断证据等。典型的新知卡包括标题、已知的知识、新知识、例子、参考和唯一编码。在右侧的新知卡例子中，标题是"卡片法之撰写新知卡"，已知的是"对于阅读需要写卡片来记录，卡片主要由标题、正文、参考、唯一编码组成"。我的新知识是"对于不同的阅读内容，卡片的形式也会不同，应根据这些内容调整卡片的形式，使之更符合内容特点。新知卡主要由标题、已知知识、新知识、例子、参考和唯一编码组成"。例子引用自杨志平的《阅读者》，唯一编码是'2023-0525-02'。

接着，我们看“术语卡”。术语卡记录的是阅读过程中出现过的陌生术语或概念。常见的术语卡结构是：标题、定义、解释、例子、参考和唯一编码。例如，我给出的一个案例是关于“唯一编码”。定义是“唯一编码是卡片的唯一标识";解释是"最常用的编码系统是时间或数字加字母，对于初学者，建议使用时间作为编码系统，因为更节省精力。作者建议精确到分钟，使用12位的时间戳"。例子就是'2023-0527-1317',它表示2023年5月27日13点17分所撰写的卡片。参考文献是梁志平的《聪明的阅读者》，唯一编码为'2023-0526-03'。

最后看“人物卡”。人物卡旨在记录阅读中遇到的人物。它的结构包括小传、参考和唯一编码。在编写小传时，需要注意记录一些基本的信息。
这段录音讲述了如何用大语言模型GPT来辅助阅读，重点介绍了人物卡、图示卡、事件卡、新词卡和经典句子卡。

人物卡的内容包括人物的生卒年份、教育背景、工作经历、主要身份、家庭、社交网络、社会关系等，如果是外国人物，还需包括英文全称。例如，这个人物卡是关于作家纳伯科夫的，他1899年出生，1977年去世，被誉为二十世纪最伟大的作家和“作家中的作家”，著作如《洛丽塔》、《微暗的火》等备受赞誉，他是一位狂热的卡片写作爱好者，同时也是《聪明的阅读者》一书的忠实读者。

图示卡以图画形式来记录阅读时的重要收获，一如俗话，“一图胜千言”。举例来说，标签为“知识创造的三个层次”的图示卡，描述了知识创造的三个层次：卡片层级(创作时间从几分钟到数小时)；文件层级，主要以与他人交谈为主(创作时间从数小时到数天)；以及项目级别，主要以进行社会交易为主，周期从数周到数年。

事件卡常用于记录叙事型文本中的重要事件，通常包含标题、时间、地点、行动者、反应等信息，例如一张描述杨志平教授自我阅读旅程的事件卡：杨教授在1998年就读于心理学系时，从大一开始便在图书馆自学并形成自己的阅读方法。

新词卡主要用于积累新词和其用法，可以帮助我们扩大词汇量和提升语感，常见的信息结构为新词加原句加造句加参考加唯一编码。例如，我从苏轼的《超然台记》中收集了“雨雪之争”和“风月之息”两个新词，并用这两个词造了句。

最后是经典句子卡，用于记录任何引人入胜的句子。它可以帮助我们提炼和积累好的句子，并在日常写作中进行应用。

以上就是使用大语言模型GPT辅助阅读的一些具体做法。
通常，我们可以采用标题、主旨句、评论、仿写、参考、唯一编码的信息结构。一个示范是：标题是"小卡片，大作用"，主旨句来自于《聪明的阅读者》第196页的内容"人类用卡片封装的世界，一切都是卡片"。我的评论是：卡片就像积木，承载的可能是一个灵感、一个巧思、一个观点，或者一个信息主块。尽管卡片体积小，但随着卡片的积累，它们可以灵活地拼接成一篇篇文章。你可以参考上述模板写卡片。熟悉后，你可以摒弃模板，根据你的写作习惯发挥。卡片的载体并不限于纸质，也可以在笔记软件中写卡片。

如果你采用电子卡片，你可能需要了解markdown语法。Markdown是一种轻量级标记语言，被广泛用于编写带格式的文本，设计目标是易读易写。许多网站和笔记软件已经采纳Markdown语法。

我们来看一下Markdown语法的一些基本用法。你只需要几分钟就能学会基础用法，比如标题、文本样式、列表、链接、图片等。在一行的开头，使用1-6个井号来创建标题，井号越多，代表的层级越低；使用星号或下划线来标记斜体，两个星号或两条下划线来标记粗体，两条波浪线来标记删除线。在列表中，你可以用星号、加号、减号来创建无序列表，用数字加英文句号来创建有序列表。链接和图片的格式很类似，只是图片的格式多了一个感叹号。最后，我们看一下引用，使用大于号来创建引用。
下面，我们来看一下，对错误的代码应该如何展示。双点号之间显示的是单行代码，而三个点号之间用于嵌入一个代码块。这些符号当中的代码可以以原本的格式呈现给大家。然后，我们再来看一下一些稍微复杂的语法：如何表示表格、横线和复选框？表格相对复杂一些，使用竖线来分割不同的单元格，使用横线来分割表头和其他行。至于表示横线，可以使用三个或更多的横杠、星号或短横线来创建。对于复选框，则可以使用一个中括号表示一个未完成的任务，用中括号加叉号表示已完成的任务。在右图中我给出了一个示例。如果您还没有完全掌握这些markdown语法，不需要过于着急。现在我们有了AI，你只需要向GPT提问，"什么是markdown语法"，它能出色地提供答案。我在PPT的右侧截图了GPT以代码框形式直观显示的效果。所以，大家也可以使用GPT来复习markdown语法。

我们想要清晰探讨到GPT对阅读的具体影响，首先需要建立在对GPT能力和局限性的理解上。接下来，我们就将从更底层的角度来探索GPT的能力与局限。首先，让我们从定义开始了解什么是GPT。邀请GPT自己来做出回答，它的回答是，GPT是由OpenAI开发的自然语言处理的深度学习模型，基于transformer架构，被广泛应用于各种NLP任务，如翻译、问答、摘要生成等等。我们可以简单地理解，GPT是一个巨大的神经网络，它从海量数据中学习。GPT并不查找文本，而是查找某种意义上的匹配内容。

例如，看看这句话：“AI最好的事情是它的能力能够预测......完，下一个单词会是什么呢？”在几十亿文字的训练之后，GBT的目标实际上是寻找下一个文字出现的概率。假设“学习”有45%的概率出现，“预测”有35%的概率出现，“做”有3.2%的概率，“理解”有3.1%的概率，另一个“做”（也是do的意思）有2.9%的概率出现。那么，你认为GPT会选择哪一个单词呢？可能有人会认为，接下来的词肯定是概率最高的，但如果总是选择可能性最高的词，我们得到的文本可能会永远很平淡。
在阅读一些有趣且充满想象力的文章时，我们经常被作者应用的一些少有人用、并非陈词滥调的词语所吸引。同样地，大语言模型GPT也能够选择频率并不是很高的文字。它是如何做到的呢？这其实是由"GPT-temperature"这个参数实现的。

"Temperature"是一个重要的参数用于控制GPT模型生成下一个选择的随机文本，也就是用于控制模型输出的多样性。这个参数值的范围通常是在零到一之间。一般来说，"temperature"越高，模型输出文本的多样性就会越大，模型就更有可能输出不常见的词汇和句子。反之，如果"temperature"值越低，则模型的输出更倾向于常见且安全的选项。比如，如果设置"temperature"为0.1，那么模型所生成的文本预测性强且一致性高。而如果"temperature"值设为1，则模型生成的文本将会具有大的随机性和多样性。

举一个实例，如果你正在使用OpenAI的API来调用模型，你就可以在设置请求中设定"temperature"值。下面这个使用Python代码的示例便展示了这一点。在示例中，我们给模型提供的一个提示(prm)，也就是某个英文文本翻译成法文的请求，然后我们设定了一些其他的参数。比如，最大输出标记数设为400，"temperature"设为0.2，并且频率惩罚和存在惩罚都设为-0.5。

我们来解释一下其他的参数。首先是"max_tokens"，它表示单次回复的最大输出标记数，一个标记可以是一个词，一个字或者是一个标点符号。然后是"frequent_penalty"，表示对训练集中出现频率高的词进行奖励或惩罚，这个参数值的范围通常是在-0.2到2之间。例如，示例中的-0.5表示模型偏向于选择频率高的词。最后是"presence_penalty"，此参数用于奖励或惩罚在输出中新出现的词，这个参数值的范围也是-0.2到2之间。例如，示例中设定为-0.5，表明模型倾向于选择已经在文本中出现频率较高的词。

需要注意的是，这些参数一般在你使用API的时候需要手动设置。如果你是使用浏览器来使用GPT，通常不需要手动设置这些参数。
我曾看到一些精彩的示例，通过指令设定GPT的参数。设定不同的参数后，GPT-4的回答表现出差异。例如，如果我们不设置任何参数，GPT-4会偏向于以严肃的方式输出答案，它使用的词汇和句子都会更加工整；当我们将温度设置为0.2，主题的一致性设置为-0.5时，它的回答将变得更为轻盈；如果将温度设定为0.8，主题一致性设置为-0.5，GPT-4的用词则会变得更为正式。大家也可以自行在模型中尝试，感受不同参数下的差异。

在AI时代，GPT可能是你首次接触并值得深度关注的模型工具。但如果你自2023年3月开始关注AI发展，可能会被各种术语搞混，例如GPT-3.5、GPT-4、或Task-oriented GPT等。实际上，这些都是OpenAI公司的产品。GPT-3.5是在2022年发布的大型语言模型，它的优点是回答速度极快；而GPT-4是在2023年发布的大型多模态模型，它能接收图像和文本的输入并输出文本，但目前OpenAI发布给大部分用户使用的GPT-4版本，尚不能接受图像输入。

这个模型展示的能力令人震惊，让我们第一次如此近距离地感受到AI的威胁：例如，在许多专业学术的基准测试中，GPT-4都展示出了人类级别的性能，例如在模拟律师资格考试中，它的得分位于前10%。

接下来我们继续探索GPT的网络浏览功能和插件功能。网络浏览功能是指GPT模型能够联网搜索的能力，由于GPT-3.5和GPT-4的知识库截止到2021年的9月，已经不能满足我们在2023年对知识和信息的需求，所以OpenAI开启了Web GPT功能，这允许GPT浏览网络，以回答最近的主题和事件。插件功能则允许GPT使用第三方服务进行计算，以获取最新的消息和信息。

当你使用这个模型时，需要根据需求挑选合适的版本。在AI阅读课上，上述的所有模型都会根据具体需求而被使用，此外，专门针对文本阅读的AI工具，如Task-oriented GPT，也会被涉及。以上就是我对GPT的简要介绍，感谢大家的聆听。
