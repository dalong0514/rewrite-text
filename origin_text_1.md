好今天呢跟大家讲一下就是XGMVSXGBT为什么就是搞这样的一个选题呢就是说因为我个人认为啊在国内能跟OpenAI XGBT或者谷歌做人工智能抗衡的公司呢我个人认为只有两家一家是百度百度确实很厉害就是它广告是广告是一回事但是它的就实力确实很厉害就是它广告是广告是一回事但是它的技术实力确实很厉害然后那另外一家呢就是清华智普就是搞XGM的而且智普它有一个特别牛逼的地方是什么就是它跟XGB的产品啊基本上是全面对标的全线对标就是说OpenAI有个什么东西品啊基本上是全面对标的全线对标就是说OpenAI有个什么东西它就基本上有一个类似的东西所以说基本上是就是一个全线对标的一个产品所以说这个公司这个公司呢或者说这个JYM这个这类的模型呢我个人认为啊是非常有前途的然后呢也是非常值得大家去追踪的就是无论你是做大模型也好就是圆大模型啊或者是多姆泰也好这个呢我觉得都是可以值得去去花功夫去了解的和学习的好首先呢我们可以看看就是我们现在这个主流大模型啊它其实呢就是分成了就是穿着风穿着风的这个就是三条线就是引扣的安乐然后呢抵扣的安乐还有引扣的抵扣的对吧分成三条线然后引扣的安乐呢这个就是什么波尔他之类的这些东西然后在这个地方Burnt earning呢也是也是百度搞的对吧就是Encode only你看这个数啊其实不是很高了你看到2021年呢这个数呢就不涨了为什么呢就这条技术路线呢已经走到头了就是或者说走到头或者说短期之内呢其实你在这条技术路线呢可能没有啥没有啥可做的东西了就是场景有限了你知道吧然后呢decode only这条技术路线就非常猛只包括我们的gpt4对吧gpt4然后呢还有包括什么xgpt啊什么的都在这条线上然后呢今天我们要讲的呢叫做他的GLM呢他是用的Encode Decoder这个架构就中间这个架构然后呢就这里XGLMGLM的模型然后我们今天呢重点呢就是讲这个和这个的PK好吧就讲了这两个的这两个PK它其实更多是不光是两条不光是两家公司不光是两家公司的PK而且呢是可以认为是两条技术线的PK就是它们的技术架构呢是有一些差异的当然这个差异呢其实可能也没有想象中那么大也没有想象中那么大但是确实有差异这是OpenAI的一条发展路径它呢比如说GP3也叫达芬奇对吧然后呢出来以后呢2 2达芬奇1吧然后呢出来以后呢二二达芬奇一二然后呢叫InstructGPT然后呢在去年的十一月份InstructGPT呢马上快一年了马上快一年了然后呢又出了一个就是InstructGPT好吧然后这是它的一个就是一个时间�好吧然后这是他的一个就是一个时间线然后我们看看智普的时间线是什么智普呢他其实啊他这个团队啊他从20年开始他的大模型呢开始出现了前面的都是就让他的起步呢比GBTE呢其实晚了两年但是呢从20年开始呢他就开始起步了这个公司啊为什么他的起步呢比GPT-1呢其实晚了两年但是呢从20年开始呢他就开始起步了这个公司啊为什么可以起步他大概是在2015年还是2016年距离我记不太清了他最早是做什么的他叫质谱对吧那其实最早是做制图谱的这家公司啊最早他其实是做制图谱的他做制图谱的这家公司最早他其实是做知识图谱的他都知识图谱呢就给他带来一个什么好处啊他有大量的数据你知道吧因为做知识图谱的同学其实都知道你知识图谱呢你得爬取爬取大量的数据对吧所以说呢他有大量数据所以说呢他有了数据作为集类以后呢哎他的起步呢其实就是哎就是非常快的他去年他在去年八月份的时候他这玩意除了130币而且呢还出了一个扣的记这种就是给VS扣的这些加插件的就是就写代码对这帮人其实就是唐洁李娟子这些人他们就是清华知识工程实验室的人对你说的很对西瓜同学好bb可以给你啊然后呢差gpt的然后出现了以后呢他们就搞了一个差�的GLM6B这个模型这个模型啊我不知道有没有人用过上上周刚出现了刚出了3.0的版本对吧3.0版本我用了一下发现还是挺好用的有一定的有一定的改进这个就是GLM团队它的一个整体的一个进阶然后呢这是一个就是我们各类大模型的一个对比各类大模型的一个对比其实我们今天主要是要比这个和这个对然后呢这个是Decoder only然后这个是Encode decoder对然后呢这个是decode only然后这个是encode decoder对然后呢这一块呢是可以进行量化的然后呢还可以进行一个快速transformer能够呢加快速度然后他这里啊写横杠并不是说不能量化只是说他的技术资料呢我们其实拿不到因为openAI呢已经怎么说快变成CloseAI了对吧就是也不怎么发论文然后呢也不怎么开源就是它的具体到底是怎么回事呢其实我们也不是特别的清楚但是呢清华这个呢所以说为什么要讲这个呢这个呢它完全开源你是能用的百度它也不怎么开源所以说这个呢对咱们自己实际的工作呢还是帮助比较大的然后啊JRM它有一个特别好处特别牛逼叫什么它可以支持国产GPU懂了吧就是说现在啊各大国企就号召大家呢用国产GPU然后呢其实啊你想用进口的其实现在A100也不太好买了对吧你能买到的也就是A10A6000V100对吧现在4090都不让买了这个有点过分对吧所以说它能够支持国产的这个呢我觉得是它的以后的一个非常大的一个亮点非常大的一个亮点非常大的一个亮点好然后呢我们在训练方法上啊经典的大XGBT的四步预训练杯条奖励模型强化学习对吧XGBT呢是把这四路呢全部都走通了但GELM啊它其实真正走就是走通了呢它其实只有这两步后面两步呢它是号称走通了但是呢存疑好吧实际上呢有点存疑因为就是各种分析发现他其实未必有他说这样所以说呢但是他前两步肯定走通了而且后两步啊就现在其实有些质疑就是说强化学习和奖励模型这块呢有可能只是充分不必要的就是未必是一个就是真正的一个标配而且呢非常的耗费耗费人力成本这两步呢其实可能我们可以认为是一个村一然后呢我们可以看一下它这个产品线刚才也跟大家看了一下就是说G2M呢它的产品线呢它其实跟就是跟XGBT呢这块呢其实是一个全面全面对标的一个过程现在呢我们就针对这些呢我们可以一个个呢跟大家大概讲一下就是GLM的这些东西然后跟大家呢做一个整体的一个一个概述好吧然后呢我们的课呢我们的课呢其实更多的是比较偏原理的我们课比较偏原理就是偏技术原理就是现在市面上有很多课他其实他也不讲原理就教教你怎么用对吧那个东西我觉得只要你正常上过大学你的英文呢过过四级水平其实呢自己琢磨琢磨呢其实你就很快呢就能琢磨清楚对吧那种课呢我觉得上的意义不大然后呢所以说今天我们课呢跟大家偏原理跟大家呢讲一些相对来说呢比较有深度的东西好吧就是这些东西呢你能自己学起来呢可能确实比较费劲或者说你查资料呢也不是很好查好我们接着继续自己学起来呢可能确实比较费劲或者说你查资料呢也不是很好查好我们接着继续这GM的一个就是发展路径啊它从3月14号开始呢XGM1.0它就发布了对吧然后6月份呢2然后呢10月27号也就是上上周对布了对吧然后呢6月份呢2然后呢10月27号也就是上上周对吧上上周然后呢它就推了两个推了两个模型对吧一个是多摩泰然后呢智能体然后呢长文本然后对话它呢有6币的有17币的然后呢还有一个所谓的什么呢agent这东西呢其实是它的一个就是非常大的一个非常大的一个亮点好我们首先看一下就是从1.0到2.0呢它有一个什么样的进化1.0到2.0啊它其实啊它就是两个进化第一个呢是长序列的支持能支持8K的序列然后还有呢快速transformer快速的transformer这个这个快速transformer呢这个快速Transformer呢就是能够加快速度就Transformer我们最后会发现它是一个作为大模型的一个呢相对来说比较平静的地方就是有一定的平静所以说呢我们把这个这样呢我们可以稍微的加速一下然后呢我们可以看一下他的这个130币呢他对应的版本呢也有就是各种版本有6币12币32币66币130币其实有个叫做什么有家公司呢叫做360这个应该大家知道吧他其实就是TALK 130B好吧它就是TALK 130B然后做出来的就中国的大模型啊其实基本上就是就是三大流派中国大模型现在就是三大流派第一个是一什么呢清华GM二百度三各类套客套客呢拉玛重灾区大部分呢其实都是套客套客呢拉玛重灾区大部分呢其实都是套客拉玛其实啊你们想想问问一个问题为啥国内套客这样玩的比较少为什么因为怕被告你知道吧拉玛说白了也就是赌Facebook不会跨过来告你但是其实就是考了这个巧好GM3呢它其实呢相比GM2呢在各个测试板上呢它其实呢又有了一个就是比较大的一个提升阿里也是套客阿里应该也是套客好吧我只能说应该啊因为我记得我在B站上说训飞我都没有说训飞我就说某家公司套客我在B站上说然后大家猜是训飞然后还有人呢去训飞法务部来告我我觉得挺有意思的说到训飞法务部给我发律师有意思的说到训练法务部给我发律师函但最后我等了两周也没等到然后呢这种就是这个呢就是各类的一个就是一个榜单这种榜单啊同学们啊有时候啊你们选情大模型是吧不要过于当真我跟你们说啊不要过于当真我跟你们说不要过于当真为什么呢就是并不是说这个榜单本身不行而是说我们有时候很多人在就是训练大模型的时候他会迎合这个榜单就专门针对这个榜单做出很多的优化比如说某川就是这样做的然后呢这个这个榜单呢这个榜单呢他有个问题就是他跟你的实际落地场景他有一定的差异就是说榜单好未必是在你这个场景上好我觉得这个地方的同学们得稍微的就是留点神好吧这个呢就是大家看一看其实其实就够了它的好处是什么基本上都是免费商业授权的好吧它这个3B和1.5B这两个呢暂时不开源这两个暂时不开源就是说我们我们也5B这两个呢暂时不开源这两个暂时不开源就是说我们我们也找不到这两个呢主要是用来干嘛你会发现它特别小对吧主要用来部署在手机端的在端上呢来进行部署的还进行部署的华为的模型呢叫做什么叫做盘古对吧它那个呢也不太开源那个呢你想用都用不了为什么叫做盘古对吧他那个呢也不太开源那个呢你想用都用不了为啥呢盘古呢更多的是他们内部呢用来支撑他们各个产品线的因为说呢他的生态呢整体来说呢是比较封闭的你看了吗一只小飞鸽就是说那个呢你不太容易接触到所以说呢我们因为我也没有接触到所以说呢因为我也没有接触到所以说呢我也不太好去做一些评价然后呢1.5B和3B呢它这个模型啊它在性能上啊已经直逼6B了也就是说它用一半的参数量甚至呢四分之一的参数量它就能够直逼6B然后呢它主要是啊就是支持国产芯片可在笔记本啊手机汽车上不输像说它其实强调什么它不是强调效果是强调清亮甚至啊可以在CPU上进行推理这是它最大的就是牛逼之处就是我们也可以想就是说我们现在这波大模型如果说你单拼效果其实可能已经都就是走到尽头了或者说那想再提升呢没有那么容易了所以说现在就开始着重于场景的落地了场景落地一个是在垂直领域上它有很好的效果然后另外一个呢就是你可以做各种就是清单化的一个部署可以做一个更多各种清单化的部署所以说JRM3呢它其实呢就在这个地方呢做了一些贡献做了这方面的一些�做了这方面的一些做了一些这方面的研究minimax其实老实说我其实没有用过minimax所以说呢我也不太好评价就是我只能评价我自己亲自做过的好我们继续就是它三呢 它强在什么东西呢一个是呢它的基座模型就是G2M这个模型啊它有更多的训练数据更充分的训练步骤和更合理的训练策略这三个其实我觉得都是一种套话对吧就是说都是可以像是说是一种万能话术然后呢他呢会在什么携带码呀知识等角度啊他其实都是有所都是有所提升的然后这个东西第二个呢他比较重要他这个呢叫 agent就是他有了一些所谓的agent的功能这个呢我们后面呢会马上呢就会跟大家呢做一些做一些展示好吧会做一些展示然后呢它还有一个更全面的开源序列就是说它呢开源的东西呢其实会更多的好吧会更多的而且基本上呢是免费商业使用的或者如果说能搞学术研究或者自己做的玩那你就直接用就行了不过这个3.0呢我也跟大家下载好了我给大家下载好了到时候同学们也可以也可以来找加我们那个助理老师微信然后也给他发给你好吧好所以我们看3.0呢它有个什么样的特点啊3.0呢它是它这个大模型啊它已经不是说一个就是纯纯语言大模型了就是它这个大模型呢它其实可以就是通过它它来调�一些工具就比如你的输入啊你先写一堆提示词写一堆提示词然后呢告诉他告诉他我的问题是什么呢你帮我查股票的价格和这个工具呢可能有两个第一个呢是查股票的查股票的查股票的第二个呢是文本转语音的就是大模型的结果呢我不像是文本我希望你给我读出来对吧它其实呢是有两个工具的然后呢你首先告诉大模型你有什么样的工具我有两个工具的然后呢你首先告诉大模型你有什么样的工具我有两个工具这种你可以写很多啊比如说你可以会有查情据报的什么对吧我有查交通交通红绿灯的对吧我都有这些模型然后呢你可以呢通过这些工具的然后你问个问题然后它自动的呢就会根据你的问题它判别出来你其实要查这个股票价格然后最后呢它就会来调用一个股票的一个接口这就是一个外部的接口最后呢把这个股票价格比如说101111月6号的价格收盘价23.16元就把这个结果呢返回给你就是大模型的一个输出所以说呢它是不仅仅是一个语言的输出它这个输出呢会有一个真实的调用接口的一个工作然后呢真实的调用另外一面的一个接口比如说我在这里那比如我再写一个提示词你帮我查今天北京的天气怎么样比如说我在这里那比如我再写一个提示词我告诉他你帮我查今天北京的天气怎么样今天北京天气怎么样然后上面呢告诉他一下我用的工具是什么然后呢有个工具的一个描述就是获得当前的天气然后呢需要输出什么呢需要输入一个位置还有一个单位就是摄氏度,还是华氏摄氏度对吧,然后我们就可以运行一下这个模型我们可以看一下对于agent的意思呢我可以简单讲一下所谓的agent呢就是大模型外面再挂一堆工具就是大模型加工具等于agent这可以给你写一下这概念其实很多人呢容易混淆其实很简单就大模型加工具你看他就会会有一个他就直接会调用这个工具然后这个工具呢就是我自己在准备一个工具这个工具呢就是用来查查气温的地点是北京然后呢单位呢是摄氏度对就是单位就是摄氏度大模型加工具的agent这是好比什么这个好比一个这个呢只是一个核心大脑然后这是一个手脚就是我两周前吧在B站上我有一个那个关于agent的一个直播然后这个视频呢现在也录下来了说专专门讲agent是什么的然后你这个希望同学你给他注定老师微信啊然后呢让他把视频的链接呢发给你好吧让把视频链接可以发给你然后呢G2M这套模型呢它其实呢它有一个比较牛逼的功能就是通过搜索引擎来给出相关答案并且呢给出引用的来源让输入呢有有据可循就比如我问他给我问他一个什么问题啊就问他今天有什么新闻对吧这个其实你说大模型他也他能理解你的意思他能理解你的意思知道你想问什么但是呢他没有答案对不对因为他也因为他训练完了以后他也不知道11月16号到底发生了什么事他这个模型的已经上线有一段时间了对吧那么怎么办呢他就会调用Five的搜索引擎然后呢把这个答案呢给得到我们可以看下它整体的一个我们可以看下它整体的一个流程它整体流程呢其实呢是三步我会着重的呢跟大家呢讲讲这三步大概是什么样的一个意思第一步啊比较简单第一步呢就比如你问他问了他一个问题对吧问了他一个问题然后他这个问题呢就直接调用搜索引擎他呢就是调用谷歌来搜索然后呢得到了得到了几个得到了几个网页对吧得到了N个网页这个不难理解然后每个网页呢他把它分成了几个片段因为网页的内容呢其实比较长的对吧他呢就把网页呢分成了几个几个片段然后呢这个片段呢他有一个模型然后叫做contraver然后这个模型呢是算计算什么呢计算问题和片段的相似度问题和段落的相似率就是说对于这些段落呢对于这些段落呢它都会进行一个什么呢它都会进行一个打分它都会进行一个打分然后呢把这种得分相对比较高的段落拿出来作为结果叫作为reference参考好这里没问题也请扣个1对于检索的结果呢它做一次过滤对检索出来的结果再用模型做一次过滤就把一些不是特别好的东西给过滤掉当然如果说你的收入索引擎啊足够强悍就是你的搜索引擎如果足够准其实你这一步啊我个人认为啊其实你不做也也没啥太大问题好然后呢我们搞完这一步了之后呢然后呢有一步呢就是说叫做提示学习就是说这些参考啊�就是说这些参考啊他不希望这些参考就是源源不断的就是原本怎么样的就出来了而且呢这些参考还有很多对吧还有很多参考就是参考对吧然后他会怎么样他会做一个样例这个呢是一个反面教材这是个反面教材然后这是呢这个真人要材就是说给它举个例子这个灰色这里举个例子就是我有参考文献一有参考文献二我的问题是什么然后我的答案是什么并且呢在这里呢做了一些引用就告诉大模型你要做什么事告诉大模型你要做什么事然后呢你就真实的问他一个你想要的问题这是一个实例这是个实例这是一个真实问题真实问题真实问题真实问题就是你告诉大模型啊我要问的问题啊是这个然后呢事例啊是什么然后我现在参考答案是什么上一步得来的上一步呢就是特质上一步就是特质上一步得来的上一步呢就是特质上一步就是特质这一步好 这就是上一步然后呢他劈里啪啦把这些给整体的融合起来然后最终得到了他的答案他那把参考文献参考文献整理汇总再输出可能为什么要汇总呢比如可能你问他有什么新闻对吧他可能对同样同样一个事情他可能有不同的角度呢来进行描述对不同角度来进行描述那么他将来会进行一个整体的一个汇总然后汇总完了之后啊这个呢只是一个大模型的能力那这个东西呢未必是符合未必是符合我们人自己想要的东西对吧未必是符合我们人自己想要的东西那我们会怎么办呢我们会再做一个打分这个叫什么呢迎合人的爱好然后呢它有一个什么呢有个打分模型这个打分模型啊它是怎么做它是说首先呢我们会收集一些高质量的反馈就点赞次数超过三次的答案就定为有效的反馈答案然后呢我们可以多挑很多的这种比较有效的答案然后呢我们可以把两个答案比如说A1 A2 A2 A3 A1 A3每个答案它都有点单数对吧然后点单数进行一个排名比如A1大于A2A2大于A3A1大于A3然后呢你去学习这个大模型呢分别来学习A1打多少分A2打多少分那这两个分数呢差异性很大也就是说大模型的来分别来学习A1打多少分A2打多少分那这两个分数呢差异性可能大也就是说大模型呢那这有一个大模型啊对这个A1的得分尽可能的偏高对A2的得分尽可能偏高对这边的尽可能偏高对这边的尽可能的偏低相当于说是做了一个打分模型而这个分数的来源就是人的标注这里没问题你扣个1所以我们总结一下它这套流程啊就是你看这个图其实还是挺复杂的对吧但是其实我们总结一下其实还是比较简单的就是这个叫做webgptwebgpmwebgrm整理思路整理思路第一步网上搜索答案并且进行过滤搜索答案并且进行过滤就打一些得分低的就是主要提高相关系主要用来提高相关系然后第二步将使用大模型将搜索结果叫reference进行汇总输出弹可以有多个然后第三步使用打分模型计算各个弹的得分放回最高得分然后呢训练样本人的点击数也就是说这个模型啊其实尽可能的符合人类的认知这个呢其实是非常类似于蓝铲但是呢它的实现呢要比蓝�Lanchain要复杂一些WY Music这是它的WebGLM的一个整体的思路其实就是利用一个思路引擎然后能够来补充很多知识然后这是它跟webgpt的一些对比啊它基本上10币的模型就已经到了175币的一个一个结果了所以说你可见啊它其实还是还是非常的非常的强悍的这是人类的水平就整体的理论人类水平呢还是有一定差异但是呢它只以10B的参数呢就能到别人175B的这个参数啊还就是比较强悍了