好的，我们已经结束了之前混乱无序的会话，现在正式开始进入今天晚上的主题讨论，即我们的第五讲。在课程开始之初，我定下的标题是“推理：成为博学者”。

然而，当我完成了整个讲义的编写后，我发现“推理”这个词并不能完全概括所要讲述的“学习”内容。这里的“学习”，尤其是PPT的学习方式，它与以往的学习方式有所不同，这个我会在后续讲述。

所以，第五讲我们就正式将标题更改为“学习：成为博学者”。今晚我们将有四节核心内容，希望大家有所收获。

在第一节，我们会讨论AI新时代，特别是以2023年3月15号作为划分时间的版本。当然，有的人也会选择2022年12月1号或者11月30号 —— 即GPT上线的那一天作为划分标志。这都是可以的。我更倾向于使用2023年3月15号，即 GPT正式对外发布的那一天作为一个划分标志。

可见，在AI新时代之前，我们的学习有一套流程。然而，AI新时代对我们整个的学习流程产生了巨大的冲击。这就构成了我们今晚讲义的逻辑架构。

在5.1部分，我将与大家分享AI新时代对我们学习逻辑的冲击，以及它引发的新挑战。

在5.2部分，我将提出一种新的学习方法论，告诉大家如何去应对AI新时代的挑战。对于5.3部分，我们会像之前的讲解一样，给出4个原则，说明我们如何更好地利用GPT来学习。最后的5.4部分，我们将提供一种工具模板，总结出16个经典的聪明学习的模板。好了，这就是我们今晚讲座的逻辑。

接下来，我们从5.1部分开始，主题是“人人都是达芬奇”，这代表了在AI新时代即将来临的一种现象。
让我们来看一下什么是博学者。历史学家博克，一位著名的英国历史学家，主要研究方向为文化史。他撰写了一本我之前在公众号和知识星球推荐过的书，名为《博学者与他们的时代》。在这本书中，他将博学者定义为掌握多个学科、对知识有百科全书般热情的人。西方最典型的博学者即达芬奇，他既是工程师，也是画家，更是生物学家和植物学家。达芬奇的许多操作和成就为我们证明了他的博学。

追溯到中国的明末清初，我们同样有一位博学者方以智。方以智出生于安徽，精通多个学科，历史学家称他是具备百科全书性质的人。关于方以智更具体的资料和生平，我在公众号上有过详细描述，在此就不再赘述。

这两位都是西方和中国博学者的典型代表。转眼到人工智能时代，我们会发现大语言模型GPT的工作方式，它恰如博学者的学习方式。

之前杨老师在讲解中提到了语言模型的演化历史。在姚老师几年前研究语言模型时，我们首先需要准备常用字词组合之间的关系，同时也需要准备几千条甚至几万条错别字的规则。

当时杨老师的团队开发出了大约几百万条错别字规则，并基于语料库生成几千万字词组合关系。

然而，我们发现这样的机制很像专家，它是一个能高效准确识别错别字的专家，但当杨老师想要提供翻译功能给用户时，然而这种错别字识别专家的能力就无法发挥作用了。
如果团队需要重新建立一个新的模型，这个新模型可能就是又出现了一个与翻译相关的模型。例如，当杨老师的团队在当年研发时，他们建立了约15个小模型，这些源自不同领域，包括统计、标注、原话语、错别字、敏感词、关键词、摘要和生存等。

当年他们用于生成的是gbti，但生成效果有些一般。除了前8个已经列出的小模型外，还有生成、改写和替换等模型。

接下来第十一个是搜索模型，第十二个是知识图谱，第十三个是句法分析，如果要叫第十四个，那就没有oci模型。在这个工作机制中，我们发现为了特定领域的特定任务，我们需要训练很多特定的小模型，这有点像一个专家的工作方式。

但是进入GPT时代，它所采取的逻辑完全不同。不再是针对特定领域训练模型或者制定语料或错别字的规则。他首先找到高质量的语料，然后进行充分的训练，有点像爆炒。例如，GPT让GPU全力运行，好像在爆炒一样，虽然这容易“炒糊”，即在一维空间把符号混淆，让生成的符号和符号之间的概率连接关系变得很容易重复且没有意义。但是在对语料进行预处理的时候，实际上他会把它“爆炒”成一个纤维的空间，生成无数的连接方式。

当我们人类在谈论我们自己的感觉方式时，我们通常储存的是5种感觉，比如对某一个符号的嗅觉特征，某一个符号的听觉特征，和某一个符号的视觉特征。但是在大模型进行预处理数据时，他会对每一个符号存储一个纤维的特征，这些纤维特征远超我们人类的心理词典，也就是说包含了视觉、听觉等等。

因此，所有可能出现的关系可能都已经储存在其中了。
那么，接下来该做什么呢？在大型模型训练完后，下一步我们的目标是让这个大型模型具备识别错别字的能力、翻译的能力、对话的能力。如果我们提供超过300条以上的指令示范，这些示范如果是多个指令，那么就会构成一轮轮的对话。这个指令集合和对话集合，构成了大型模型的能力，也就是GPT的能力。

昨天，杨老师和团队整理了可能是中文领域最大的指令集合，它总共拥有261万条中英双语的指令，我们拥有了261万种可能性。然而，这样的结果带来的代价是什么呢？代价就是，大型模型的能力可能过强，导致其训练的成本非常高。工程师告诉我，昨天晚上训练了整整12个小时，到今天下午的时候训练的进度还不到7%，这显示了指令集合对于模型训练的重要性。

当我们希望大型模型具备一种新的能力时，我们就会编写一种新的指令集合。团队采取了非常聪明的方法，利用他们强大的信息分析能力，找到了市面上所有的指令集合，进行数据整理，最终形成了261万条的指令集合。这可能是目前中文领域最大的，英文领域也应该没有这么大的指令集。现在，我们开始让大型模型具备各种能力，这就是大模型工作机制。

我们发现出现了一个有趣的问题：这种工作方式并不像专家的工作方式，反而更像博学者的工作方式，并向我们带来了两个巨大的挑战。

第一个挑战是每个人都需要迅速成为博学者，否则就会被善于使用GPT的人打败。

举例来说，杨老师曾认为，心理咨询这个行业因为需要反复与人打交道，所以是最难被GPT替代的行业。然而，自从我和团队开始研发大型模型后，我现在的看法是，心理咨询行业反而可能是被GPT迭代最快的行业。
为什么会这样呢？众所周知，心理咨询师的成本非常高，而训练过程又非常长。一个优秀的心理咨询师可能需要花费十年时间方能培养出来。如果你在北京寻找这样的咨询师，可能一周只能咨询一到两个小时，而你需要为这一到两个小时付出的成本，极有可能在1000到2000元之间。一年下来，你可能就需要花费一两万块钱，并且你还不能24小时获得咨询师的指导。

然而，像杨老师这样的大语言模型，可以更好地完成人们需要的情绪安抚功能。

在未来，这些大模型将具备巨大的可能性。在星期天的人生发展咨询师集体培训上，我给参训的咨询师们布置了一个任务，那就是集体合作撰写一份人生发展咨询师的专用指令集合。假设这些指令集合有420条，当我们完成撰写之后，初级人生发展咨询师的工作可能会被这些大模型取代。

我们需要明白，在任何领域，只要你掌握了写指令的方法，例如，如果你能编写这420条来自各种实践经验升华和工作流程总结的指令，则大模型会初步具备专业领域的能力。这对我们的世界将造成极大的影响。

无数以符号语言为主的职业，如心理咨询师，甚至可以说是以书面语言为主的众多职业，将面临这样的冲击。只需要一个大模型和420条指令，就可以开始掌握某个领域的基本能力。
所以我们的整个学习方法论，要面临的是一个无比巨大的挑战。好的，那么第二个大的挑战是什么呢？那就是大模型GPT。在掌握了420条心理咨询的指令之后，大模型实际上很容易取代初级的心理咨询师，比如那种接受电话热线的咨询师。你会发现，未来大模型做心理咨询的效果，必定会比利用心理热线电话的效果更好。然而，其效果无法与顶尖级别的咨询师，比如拥有几十年经验的姚老师相媲美。这就是我们在GPT时代面临的第二个巨大挑战，就是如何在大模型的冲击之下，让大模型本身具备专家级别的深度和洞察力。有人可能会觉得这是做不到的，但杨老师今天所示范的学习方法论告诉你，大模型是可以做到的。其实，大模型不仅能实现电话心理热线的水准，它甚至能做到一些非常高级的事情。这就是杨老师今天为什么会说，错过这个讲座的同学可能错过了一个亿，这些都是杨老师的一些独特见解。

好，这就是我们接下来要分享的。接着我们来看看大模型如何实现这些高阶的技能，这实际上是基于它的底层能力。

那么大模型最关键的底层能力与学习相关是什么呢？其实这里有三个关键的能力。在讲这三个能力之前，我们先要谈一下在GPT时代，为什么说博学者对专家更有利，为什么博学者比专家更有优势？

实际上，我们的标题最早叫做推理，而不是学习。人类的学习其实存在两种模式，第一种是推理式的学习，它是非常经典的学习现卖的模式。大模型就是走的这种路径，你需要给它提供一些示范的数据，这些详细的数据能让GPT生成的质量非常高。所以，杨老师称之为推理式的学习，它就是立即学然后立即用。但是在GPT时代，我们人类的学习方式又是什么呢？

我们的学习方式实际上是即时的学习，而且以死记硬背为主。在GPT前的时代，在AI还未出现的时代，即2023年3月15号之前，专家之所以能够征服非专家，其实就是因为他们对这一领域熟练掌握了大量的硬知识，这些知识成为了他们的库存记忆。
在上一节课中，我们介绍了一部分知识，被我们称为"常识工作记忆"。一个专家在某一个领域工作时间很长，他的大脑中，就像在黑质液旁边，存储了成千上万的信息，可以方便遗被提取。

我们可以借用电脑来理解，这就如同电脑的缓存，可以在第一时间从缓存中加载到内存条中。这种学习方式就是专家依赖的记忆式学习，偏向常识工作记忆。但值得注意的是，在21世纪GPT时代，记忆式学习似乎失去了它的意义。因为目前GPT所具备的常识工作记忆能力、短时记忆能力和工作记忆能力都不强。这个问题在GPT5.0、GPT6.0、GPT7.0的版本更新中得到了解决。

事实上，GPT现在最强大的能力并不是记忆式学习，而是推力式学习。也就是说，它能够在实时对话中，逐步生成出我们想要的答案，帮助我们更快速地去学习。

因此，这种学习模式反而更有利于博学者。博学者能很容易判断信息的真实性，而一个依赖记忆的专家却不太容易做出判断。这点我相信大家已经明白了。

我希望大家一定要购买杨老师的那本书，因为这本书总结了100个学科，这是我们所说的无缝岔路广告。这也相当于是GPT时代的一个精神象征。

推理式的学习是以推理能力为基础的。杨老师在他的人性系统论中总结了这三种能力。我们人类通过一系列的感知符号，进行以下三个操作。

第一个操作叫做"对比"，比如，这个是不是黑色，而是白色。这就是对比。

我们人类通过对比，学会了大量的概念。任何一个概念都是建立在对比的基础上的。如果不理解什么是白色，那么就无法理解黑色的概念；如果不理解粗糙，就无法理解精致的概念。

如果不了解白天的概念，就无法理解黑夜的概念。这是第一种操作。
我们在进行推理的时候，第二种操作是什么？它叫做穷举，亦称列举。举例来说，我们所知道的一周有7天，包含了第一天、第二天、第三天、第四天、第五天、第六天以及第七天。再例如我们手中的手掌，有1到5五个指头，这些基本的列举操作也是我们人类底层的能力。

第一种操作和第二种操作相对容易理解。

第三个操作，也许会让一些人觉得难以理解。那么，第三个操作是什么？它就是反事实推理，也就是我们常说的“如果…那么”。

你会发现，第一种和第二种操作其实是脱离了情景的，没有嵌入太多的上下文信息。而我们人类生活在时间中，活在空间中，是寻求意义的动物。我们受到自己的情绪影响，我们是受到他人的人际关系给我们带来困扰的，我们是容易感到烦躁的有血有肉的机器人。

那么，这一操作过程在我们的大脑中是如何完成的呢？那种最小的操作又是如何嵌入到我们人类的情景信息中的呢？实际上，这个过程就是反事实推理。

反事实推理是我们人类三大基础操作之一。我们通过模拟世界，预测如果在某种情景下，我会有怎样的行为，这就很好理解了。

基于此，我们可以看到GPT在学习上的三大核心能力，并非强调死记硬背，而是强调现学现用。这三大能力，即对比能力、列举能力和模拟能力，是建立在人类三大推理基本操作之上的。我们将会重点介绍这三种能力的特性以及其原理限制。
对于各类事物的比较，大语言模型GPT的能力大致上可以打80分，准确度相当高，仅次于我们前一课程讨论的文本统计能力。GPT的比较能力之所以强大，根源在于其本质上是一个向量矩阵。这个向量矩阵是通过经过数千万次的推理操作生成的。在这些推理操作中，大多数都是执行对比操作。所以，GPT的对比能力非常强大，准确度极高。

人类对比实质是对概念背后的本质进行比较。但是，GPT的比较方式和人类的不同。例如，我们人类在比较一位男老师和一位女学生时，我们会基于性别，年龄，外貌等面向去做比较。然而，这些比较是基于人类现实生活的全面思维。相对应的，GPT的比较则在一种完全利用人类未发现的微妙关系的向量空间中进行，甚至能够比较出科幻小说中的前生、现生和来生之间的关系，这使得GPT的对比能力相当强大，并且会产生非常神奇的影响。

在实际应用中，GPT对比事物能力可以高达90分，无论是对比概念，对比人物，对比事件，对比文学作品，还是对比艺术作品等等。然而，GPT在对比能力上也有一些限制。首先，它有知识更新限制和数据偏见，同时，缺乏基于常识的推理能力。其次，一旦需要处理的文本变长，GPT就可能因其较差的记忆能力，使得最终的比较结果变得不那么准确。

因此，尽量让GPT在其工作范围内进行对比。例如，如果你希望得到一个重要的答案，尽可能地让GPT在四步内得出答案；如果超过四步，未来的视觉结构可能会受到稍微的影响。
好的，我们现在继续。GPT的枚举或列举能力实际上与其数据集有关。因为GPT已经拥有了整个互联网上20%左右的关键知识，这20%的关键知识除了包括人们欣赏的文学作品外，还包含了一些我们日常很难掌握的知识载体。

比如说，GPT拥有GitHub上的所有代码，如果你是个编程新手，查看GitHub上的代码可能会让你感到困惑。类似地，如果你对音乐一无所知，你可能也会觉得阅读乐谱很困难。然而，GPT不仅拥有GitHub上所有的代码库，也拥有世界上最主要的音乐网站的曲谱以及歌词库。此外，它还拥有大量的文学作品，许多书籍，以及众多学术论文库。这些信息已经通过重复的计算形成了一个庞大的知识矩阵。

在这个知识矩阵中，如果一个人想要快速生成新的列表或清单，受限于他们已有的知识结构，这将会非常困难。然而对于GPT来讲，这只是一个简单的符号搜索过程，因此它生成的结果极为理想。

例如，我们可以给GPT一个指令，让其列举出某个年代美国的名人。这对我们来说需要经历很多步骤，但GPT可以做到，而且准确度大约达到80%-90%。

此外，比如我们要出数学题，以往我们需要花很多时间设计题目，但用GPT，我们可以直接给出指令，比如请编出一套由易到难的数学题，并需符合初二学生的学习水平。这在一定程度上实现了个性化教学。传统的个性化教学通常是使用预先准备好的题库，但现在，你可以让GPT为初二学生生成10道数学题，然后让你的孩子去做。做完后，你可以告诉GPT，他生成的题目难度过大或过小。这样就能根据反馈来调节题目的难易度，进一步提升个性化教学的效果。
我的孩子在初二，他做题的表现并不理想，特别集中在某几道题目上。我想要你能生成10道比他做的题目稍难，以及10道稍易的题目来提升他的成绩。在这样的请求下，我们在实现一种超越传统教辅老师的方式。这就体现了对比能力。

此外，对比能力还包括解决一些算法和密码问题，这是我们人类相对较弱的能力。人类通常不擅长处理感性之外的符号，例如代码、数学、算法和密码，这些理性的能力在人类中不常见。

我们有一群被称为数学家的专门参加数学奥赛的人，有一批专门从事算法的人，他们被称为算法工程师或算法专家，我们也有专门研究密码的密码学家，他们帮助我们解决一些复杂的问题。然而，在我们的日常生活中，我们也大量使用数学、算法和密码等。在这部分，GPT可以帮我们无限地列举和组合，这是他的强大之处。但仍受到计算资源和非专业部分算法的限制，尤其是一些极小众的问题。

让我们记住一点，GPT对那些在论文、书籍、维基百科中被充分训练的算法有很好的处理能力。因此，我们最好尽可能地用英文向它提问，因为许多专业的算法并未翻译成中文，即使翻译成了中文，也可能无法准确地翻译回去。

许多算法，甚至包括一些特殊符号，在使用中文进行提问时，效果可能并不理想。如果你向它提问："请给我列举人工智能领域的一个算法"，实际得到的结果可能比较一般。如果你用英文询问："请列举自然语言处理中，经常用于将字词转换为向量的10种算法"，你会发现它的回答会更为精确和理想。
让我们首先理解大语言模型GPT的一些限制。其次，它无法处理大规模的问题，会表现出不一致性，并且对于问题的理解存在一定的局限。再来看它的第三项能力 - 模拟能力，这项能力大约是70分水平。我们的介绍会按能力的强弱进行，首先是强大的对比能力，其次是较强的列举能力。

但是，当涉及到GPT作为一个人工智能的模拟能力时，它的表现就没有那么强大了，但已经达到了我们人类可以很好地使用的程度，大约是70分水平。

以设想性任务为例，例如，让它设想某个历史事件的可能结果，设想它成为文学作品中的主角，设想它实施某项经济政策，进行某项理论假设或进行人际关系分析等等，这些都是它的模拟能力，与前面的能力有很多相似之处。

接下来，我们来了解GPT模型在学习方面的三大核心能力，其中GPT最擅长的是推理式学习，这种学习方式赋予了它像学者一样强大的理解和推理能力。

我们将推理学习和GPT的功能结合起来，把它总结为对比能力、列举能力和模拟能力三大部分，它们背后实际上都是GPT的三种符号基本操作：对比操作、列举操作和反事实推理操作。

在GPT4.0版本之前，GPT在这三大方面的能力都只能说一般，无法与人类相比，特别是在反事实推理能力方面。但是，进化到GPT4.0版本后，大多数时间内，它已经达到了一个大学本科生的水平。虽然还不能达到像莎士比亚那样的推理水平，但通常已经能胜任一个大学本科生的推理任务了。

至此，我们第一部分的内容结束了。我们今晚的重点非常多，但这只是我们整个主题的一部分，如果写成书稿，可能会有3万字的内容。接下来，我们将会进一步让大家意识到在21世纪，传统的专家式学习受到了GPT的巨大挑战。我们每个人或许都需要像杨老师一样适应这种变化，成为一个终生的学习者。
在第二节课，我们正式提出了一种新的学习方法论。在21世纪的2023年3月15日，我们探讨如何更快、更好、更高效地成为一名博学者，这就是我们的新学习方法论。接着在第一节课中，我们回顾了上一节我们介绍的IQ框架，我们首先用心理学和IQ的框架来理解心理学专家。同时，杨老师在前面的课程中也给大家介绍了心理咨询师的特定技能集合，是为我们理解这些专业人士的特质提供了指导。

无论是心理咨询师、人生发展咨询师，还是计算机科学专家，各个领域的专家都会使用书面语言和符号语言。杨老师已经很明确地向大家解释过，如果我们想让大模型，例如GPT，具备心理咨询师的某些能力，我们需要将其整理成一个包含420个指令的集合。按照这一方式，我们的大模型就会初步具备心理咨询师的能力。

在整理模型的过程中，我们可以使用ak的框架来帮助我们，这是整理过程的最关键、最微妙的一步。如果你不太了解ak的框架，你可能会认为它平平无奇，但实际上，这个框架是杨老师的一项重要发明。它用来帮助我们理解一个专家在某个领域的知识结构和内容。

