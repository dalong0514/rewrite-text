然后呢它第二个模型呢叫做图文理解叫做Core VLM这个呢主要是ZOJ VLM这个呢主要是对应于GPT-4主要是对应于GPT-4比如它要做什么呢你给一个提示词就是说你描述一下下面这个东西是什么噼里啪啦告诉你这是一个麻婆豆腐对吧然后呢在中国非常流行的四川菜对吧第二个对它呢这个呢就相对说是可以对图片呢进行一个比较比较深入的一个了解然后它呢也推出了一个COGVRM你可见它这个紫色的边框是它的能力他这个能力你可以看到他是非常强悍的叫做八边形战士射八边12345678910111213边形战士就是他的各种各种能力都是非常都是非常强悍的我们一看他这个能力大概是什么样子的比如说他有个对比啊他论文有个对比比如同给同样张图你给同样张图你问他这张图上面啊有几个有几个树有几个房子有几个房子然后呢这笔记四呢就会告诉你有三个然后他呢就告诉你有三个然后他呢就告诉你有四个为什么呢因为他发现这里有个角对吧这里有个角然后这个角呢后面呢其实背后呢其实是个房子但是呢GPT-4呢没有猜出来对吧但是这个是他自己举的例子但是我个人认为这个例子你也别太在意了为啥呢你凭什么说这个角是房自己举的例子但是我个人认为啊这个例子啊你也别太在意了为啥呢你凭什么说这个脚是房子对吧还有可能是个人的帽子或者个别的什么东西对吧这种反正是卡通图嘛你也你也说不清楚当然他证明他自己有这样的能力就是说他可以对图像的观察能力呢可能会强于这不意思啊他是这样自己说的然后你对图像的观察能力呢可能会强于这批次他是这样自己说的然后他还给你解释为什么因为他说这个地方呢只露了半个角他还能够给你解释为什么他认为是四个房子然后呢他还可以呢做什么呢比如说你给他了一张图你告诉他你来帮我描述一下这张图然后他就告诉你这张图大概是一个是一个什么样的场景它其实基本就是什么叫做看图说话其实就是一个看图说话的一个场景这个模型呢还是非常厉害的非常厉害的然后呢他甚至还可以看图啊来做作业就比如说你就问他两块苹果加一块苹果等于什么就让图片给他他才告诉你等于三这个你们如果养过小孩其实你都知道这个就是那种儿童就是你教小孩加研法的时候其实一般都用这种这种有趣的图片对吧他也能够把这个东西完全给理解这个呢其实是一个非常非常厉害的厉害的一个厉害的一个能力好吧包括这个呢也是他可以看着图呢进行一些进一些数化然后他还告诉你衣服的坐标在什么地方相当于说是连就是目标检测的功能呢他都可以给你完成这个多模态的能力呢这是典型的多模态能力啊这个多模态能力是非常强的我们看了一下这个效果以后呢我们可以大概了解它的这个这个原理啊它这个原理呢它这个原理呢其实很简单当然理呢其实很简单当然也不是说很简单就是说没有想象中那么难没有想象中那么难比如说啊你有你有它手上你会找到很多就是图片文字队图片文字队就是一张图片对应着它的描述图片对应它的一描述嗯图片对应他的一张让我们图片文字对然后呢你把这个就是文字这一侧每个 token啊你可以对应对应成一个向量对吧我的引白顶你每个 token 呢你可以对应一个向量然后这就是一个文本的向量序列那就有文本的向量序列然后呢你把这个图片呢你也可以变成个向量序列就用VIT encoder这个VIT呢是一个专门的一个模型就是用Transformer来做做图像的一个模型这个我们之前也讲过在B站上对这个模型如果感兴趣的话你可以加我们助理老师微信到时候他把这个视频链接也可以发给你这种课很多时候都是一环套一环的然后这个东西呢出来了以后呢也是个向量序列然后把这个向量序列呢过一个LMP进一个进一个转换主要是让这个变成一个同维度的好吧所以说这是个向量序列这也是个向量序列然后把这两个向量序列呢都给拼在一起拼在一起这是个向量序列这是个向量序列然后把这两个向量序列呢我给拼在一起拼在一起这是相当序列这是相当序列然后把这两个序列呢全部拼在一起成了一个非常长的一个非常长的一个相当序列好 然后呢非常长相当序列了以后呢然后呢我们怎么做呢它这个做法呢很牛逼啊他就说把这个相当矩阵他还是爱做就是他还是爱做叫做JBT类似的类似于JBT类似于预测通过这个图片我们来预测这个文本比如你输入这个图片了我们来预测这个文本比如你输入这个图片了以后预测A然后把图片夹A输进去然后预测Fox然后图片夹A和Fox预测E子像GPT一样一个词一个词的一个词一个词的预测只不过他做的时候呢他比较就取巧了什么意思呢首先输入一个文本对这是一个文本的一个项链然后呢这里呢是图像的项链文本加上图像项链然后把这两个项链啊放在一起串在一起做Q串在一起做K串在一起做K串在一起做V然后进行一个多抽头的attention这样的话这个attention呢它其实是有V的加权就像你说是把图像信息和文字信息融合在一起了把图像信息呢和文字信息呢给融合在一起了因为它放在QKV都是图像和文本图像和文本的这个串联对吧�文本的那个串联对吧串联然后串联完了以后呢然后呢再分开来做文本呢自己做FFN然后呢图像自己再做FFN这个就是一个就是Transformer那个那个潜会神经网络然后再分开来做Transformer潜会神经网络然后最后呢串完分开之后呢结果再串联起来然后再走它整做Transformer的前回直进网络然后最后呢串完分开之后呢结果再传递起来然后再走它整个架构啊就是一个Transformer的架构就是Transformer的架构它简单是Transformer的Decoder的架构就是使用了一种技巧把不同源的信息merge在一起这个不同源的信息呢主要其实就是指图像信息还有文文信息然后merge呢它的公式就在这个地方其实这个公式很简单啊就是把它们首尾的串联在一起收尾串联在一起这样的话你输入张图片将图片的就会来预测啊他对应生成的一个文字对吧你训练样本就这样设置的通过训练样本就通过这个文文本把这一串字一个个的给预测出来所以说你给它输入一张图片它也会倾向于把这些字呢一个个的给你预测出来然后呢还有一个比较强悍的模型叫做文生图模型就是说刚才其实图生文对吧这看图是图生文然后呢这里呢是文生图模型就是说刚才其实是图生文对吧这看图是图生文然后呢这里呢是文生图就是你给个文字然后他就帮你把图片给画出来这个呢在一些美术场景呢其实用的非常多美术场景用的非常多就是OpenAI呢其实出了一个自己的一个模型然后呢支普呢其实出了一个自己的一个模型然后呢支普呢也出了一个自己类似于CoreWave这个自己的这样一个模型然后呢我们可以看它的原理它的原它的它的这个就是就是OpenAI的这个这个原理呢其实也很简单它就比如说你输入一张一只可爱的小猫对张一只可爱的小猫对吧一只可爱的小猫然后呢它就会把这个小猫给token对吧一个文字序列对然后变成一个文字的向量序列文字向量序列然后在这个样子呢跟前面讲的呢其实有一点不一样前面呢是用clip模型的直接把文字把图片变成相应序列但这里呢并没有这里呢其实有个模型呢叫做bit我不知道同学知道这个模型没有这个模型没有这个模型它是它什么意思呢它先把这个图像先把这个图像进行编码变成一个离散化的东西比如说1 5 9100等等变成一个离散化的token就一张图像先变成一个token这里呢是4xtoken就一张图像先变成一个token这里呢是四乘四将来把这个图像呢分成了四乘四份然后呢每一份呢对应于一个token每一份呢对应于一个token还能这样分然后分完以后呢把这个token呢再找到它对应的向量然后搞成一个向量序列然后呢来进行预测就是说你输入一只可爱小猫的头像然后呢分别来来预测各个图像的token输入文字然后用JPG的原理预测图像token预测就是这个位置的token图像token预测完了之后呢图像都预测完了之后呢通过解码器回复成图像就通过这个通过这个decode然后呢直接恢复成图像这就是它的原理为什么这里不用clip也是在于这个地方就是用clip了以后啊你这个向量序列你很难逆生成一个图像但是通过token的方式呢它这个项目序列呢是能够变成一个能够变逆就是逆生成一个图像的这个就是为什么它用这种方法来来做的原因好那个就是OpenAI不是不是那个质谱呢这上面呢是openAI的方案这是openAI的方案然后下面呢这个呢是质谱的方案质谱的话它是什么意思呢其实差不多它也是比如说一张图像它也是一张图像然后呢我先把它token化也是用的这个就是BIT的模型用BIT的模型好token化token化了以后呢然后呢来预测就是BIT的模型就是BIT的模型好token化token化了以后呢然后呢来预测只不过呢它这个预测啊它是可以就是看到就是前面的东西的明白我的意思吧就是它是可以就是看到一些比如你预测S5的时候它是可以它是可以看到前,比如你预测S5的时候,它是可以看到前面的一些东西,就是能看到的视角跟这个是不一样的。这里的视角是完全的一根线,就是只能看到前头的。就是只能看到前头的明白吧这个呢它其实呢看到东西呢它这个视线大小呢跟之前呢其实是不太一样的就仅此而已整理方案呢其实也是比较类似的然后BID这个模型啊它呢是需要离线训练的就是把图像编码化它怎么训练呢它首先假设我这个图像我总共呢有812个编码好吧然后我这个图像呢我先通过一个编码模型比如说四乘四对吧四乘四然后呢找到每一块呢都对应于一个编码对吧每一块都对应一个编码然后呢先通过这个编码模型然后呢这个呢要能恢复回来然后就求这两个的如此两个的Lose两个的差异就是说先编码然后再恢复然后这个编码我们把这个编码器呢训练完了以后呢留着然后呢对图像进行编码然后呢你想通过这个编码呢恢复成图像然后通过这个Decoder我们呢可以再恢复成图像这个就是DIT模型需要做的事情编码呢,恢复成图像,然后通过这个Decoder,我们可以再恢复成图像。这个就是DIT模型需要做的事情。它除了这个,这个编码器和解码器都是离线训练好的,都是离线训练好的。在这里呢,它其实只是用了而已,只是用了而已只是用了而已然后呢我们除了就是那个文生图和图生文其实我们都讲完了对大概讲了一下然后呢还有一个呢就是比如写代码这个可能是一种一种刚需啊它这个代码呢能写的非常长写的8192个序列然后呢各个主流的编程语言呢它都是有比较比较强的一个提升的然后它这个就是涉及到编程语言它涉及到编程语言其实大概是这样的Python呢差不多占了26%然后C++呢是28就是各个语言其实大概是这样的Python呢差不多占了26%然后C++呢是28就是各个语言的一个就是比例比例分析现在可能但是我觉得可能现在写C++的人写C的人是不是比较少了可能大量的都是Python和Java对吧大量的反而是Python和Java的也多然后它这个模型其实很简单比如说你在Python里头你有个比如一句话for i in range什么什么就是写了循环然后它就把这个它就把这个当成一个语言序列当成语言序列来直接预测下一个token是什么这个就是完全是一个什么完全是一个GPT的架构完全的就是一个GPT的一个架构只不过它这个预测之后它这里有一个超了一个进道在这个地方有一个把这里呢跟DN个呢然后它这里超了一个进道然后直接连起来然后来预测N加1这里说错了在这个地方一个把这里呢跟Dn个呢然后他这里超了个近道然后直接连起来然后来预测n加1这里说错了n加1这样他来多了一个自由变量多了个自由变量然后呢来来预测下个词这个这个自由变量什么意思就是说你在GPT里头啊比如说GPT里头啊比如说GPT1 2 3 41是预测2,2是预测33是预测4,4是预测5,对吧然后呢,code1呢,什么意思呢和这条相对来看,什么意思呢1 2 3 4这条相对它什么意思呢一二三四然后呢二这个位置专门有个编码来预测二三这个位置专门有个编码来预测三就是在预测二的时候呢它拿一个编码放在这里然后把二给预测出来然后再放下来这里呢会多一个编码就是这里呢多了一个位置的编码放在这里然后把二个一次出来然后再放下来这里呢会多一个编码就是这里呢多了一个位置的编码这当然这个东西呢是非常细节的东西了就非常细节的一个东西了然后他除了这个就是做一个这种模型的大概的原理大概像这样就是玩具基本上就是GPC的架构你可以认为然后他还可以做一个什么他可以做一个代码的主翻译就是说你给他一个啊 java 代码java 代码然后呢他直接呢会帮你呢把它翻译成啊对应的一个 python 的代码这其实就是个机器翻译的过程对吧那其实也是一个类似于 gpt 的过程对吧这里呢整个呢当成�于gpt的过程对吧这里呢整个呢当成一个输入然后呢输出呢就是另外一个语言代码好这个呢就是我们今天晚上大概大概讲解的一下就是当然今天晚上讲的比较粗啊就讲了各类的一个模型的就是 glm 这个系列质谱这个系列大概的一个一个功能的相对的原理今天晚上讲的比较粗因为你每一个模型如果细讲的话呢其实都是一节课这个呢我们在后续的课程里呢我们会后续呢会就是慢慢给大家呢把每一个模型的细节呢给加上今天呢就是跟大家呢相对来说讲的讲的比较粗一点就是一个一个轮廓然后整体来说呢就是说它这个牛逼的地方在什么地方呢就是说你用GBT的时候它首先不开源对吧它首先不开源然后呢另外一个呢还有安全的问题然后你都是有一个类似于就是国产的就是国产的平地的就是他买他的特斯拉我买我的比亚迪对吧就是说并不见得比他差并不见得比他差而且呢还完全开源然后呢他还有个好处呢就是他的生态位特别好他的生态位他别好它的生态位它能够支持国产GPU这个其实我觉得以后这个以后呢会是一个非常强大的优势为什么呢因为算法性能上算法效果上这个东西其实你慢慢就能追上了但是呢或者说你稍微差一点对你实际工作呢其实影响不大但是呢能够支持国产GPU这个呢以后会成为你一个落地的一个非常重要的一个点明白吧那另外呢它支持一个什么呢它支持一个叫做小型化部署它支持一个小型化的部署它有1.5B还有3B的这种模型这种呢小型化的部署还有1.5B还有3B的这种模型这种小型化的部署呢也是非常重要的也是非常重要的因为你要是没有这个小型化部署你很多端的设备你是不能用的比如说你要搞安防对吧它怎么就不能联网对吧或者是拖网的环境下比如说你要不在手机里头然而你手机没有网就不能用了吗对吧或者说你用在手机里头你有你手机没有网就不能用了嘛对吧或者说你用在手机里头你有隐私的考虑就是我我不希望我的内容被手机厂商知道那么他只能在端上部署那么这种1.5B和3B的模型呢它的作用呢其实就会非常的大了好这呢就是我们今天的课上的一个一个内容吧然后呢我们现在呢就是我们今天的课上的一个一个内容吧然后呢我们现在呢就是就是也在自己做一些课程啊也自己做一些课程比如说呢我们会有我们的一个就是多模态课程大纲这个大纲呢更多的就是各种多模态比如图生文啊文生图啊然后呢step diffusion扩散学习啊赛模型之类的这个呢对我们这个大纲的感兴趣的同学呢可以加我们一下注意老师微信好吧这是我们的就是多模态大纲然后呢我们除了多模态以外呢我们其实呢还有一个大模型的训练营的一个大纲这个呢主要是就是讲就是训练一个语言大模型就是刚才那个呢是偏向多模态就偏向视觉然后这个呢是要是就是讲就是训练一个语言大模型就是刚才那个呢是偏向多模态就偏向视觉然后这个呢是偏向于就是文本语言好吧文本语言然后这是两个训练营的课程然后呢有些同学当然这两个课程呢可能需要你有一定的记忆学习的基础啊那有些同学说了那我对记忆学习呢我完全�那有些同学说了那我对记忆学习呢我完全不知道怎么办呢我们还有个零基础零基础入门的一个课程好吧这个呢这个呢就是说你是完全小白你甚至连编程都都不熟都不会你报我们的班然后你来学习呢都没问题好吧完全是面向零基础的并且你报这个班以后啊他已经囊括了刚才介绍的大模型多么看就说你想真的系统学习然后能够掌握前沿技术的话呢你来报这个班呢其实是比较合适的现在的价钱也是比较优惠的然后呢如果说对我们过往的课程对我们过往的一些公开课还有今天的课程呢比较感兴趣的啊想要学视频呢或者PVT啊之类的叫我们助理老师微信好吧然后呢到时候他会把这些东西给你如果说你不知道助理老师微信是多少的你可以让我翻聊天记录然后呢或者说呢关注一下我就是关注一下这个B站号然后呢他就会然后看一下私信然后就会把这个微信号告诉你然后你加一下这个微信号就可以锁到一些资料或者说对我们这个课程的感兴趣呢你也可以找他要好吧好那我们今天课程呢就先到这个地方同学们下课